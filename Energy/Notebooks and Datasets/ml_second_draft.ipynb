{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba636777",
   "metadata": {},
   "source": [
    "# ADDENDUM: Predicting The Trend of the Price of Wheat\n",
    "\n",
    "This section of the project tries to predict the trend of the price of wheat in the next five years through the `Random Forest` machine learning model.\n",
    "\n",
    "First of all, let's define what the `Random Forest` regressor model actually is. The `Random Forest` model can be considered as an upgrade on the `Decision Tree` model and is essentially a series of decision trees. A `Decision Tree` regressor algorithm makes predictions using a structured binary tree. The model operates by recursively dividing the data into subsets according to the most important attribute at each tree node.\n",
    "\n",
    "However, the `Decision Tree` is prone to underfitting, where predictions perform excessively poor, and overfitting, where predictions perform excessively well, *if* there exists no bounds on the tree's depth. This is where the `Random Forest` model comes in. By averaging the predictions of each component tree, the `Random Forest` generates a prediction. Compared to a single decision tree, it typically has far higher predictive accuracy and performs well with default values.\n",
    "\n",
    "With this in mind, let us apply the theory to our wheat price dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c150091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split  # to be used to optimize tree depth\n",
    "from sklearn.metrics import mean_absolute_error  # to compute the mean absolute error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81a93055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DATE', 'PCU325311325311', 'WTISPLC', 'WPUSI024011', 'PWHEAMTUSDM',\n",
       "       'PCU3253203253201', 'WPU02550304'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('PCU325311325311.csv')  # fertilizer\n",
    "df2 = pd.read_csv('WTISPLC.csv')  # crude oil\n",
    "df3 = pd.read_csv('WPUSI024011.csv')  # agricultural machinery\n",
    "df4 = pd.read_csv('PWHEAMTUSDM.csv')  # WHEAT\n",
    "df5 = pd.read_csv('Pesticide2003.csv')  # pesticide\n",
    "df6 = pd.read_csv('seeds.csv')  # seeds\n",
    "\n",
    "df_list = [df1, df2, df3, df4, df5, df6] \n",
    "merged_df = pd.DataFrame()\n",
    "merged_df = df_list[0]\n",
    "\n",
    "for df in df_list[1:]:  # merge the dataframes on the date column and find biggest overlap\n",
    "    merged_df = pd.merge(merged_df, df, on='DATE', how='inner')\n",
    "    \n",
    "merged_df = merged_df.dropna(axis=0)  # drop any potential NaN values\n",
    "    \n",
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91257487",
   "metadata": {},
   "source": [
    "In machine learning, `y` is conventionally defined as the target value, whilst `X` is defined as the \"features\", or the training data. In this case, `y` is wheat prices and `X` is rest of the accounted variables exhbited *apart from* the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fe33403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    118.157134\n",
       " 1    115.775953\n",
       " 2    133.484492\n",
       " 3    130.649980\n",
       " 4    130.056604\n",
       " Name: PWHEAMTUSDM, dtype: float64,\n",
       "    PCU325311325311  WTISPLC  WPUSI024011  PCU3253203253201  WPU02550304\n",
       " 0            177.6    30.72        166.2             100.0        120.6\n",
       " 1            173.8    30.76        166.5             100.0        121.5\n",
       " 2            175.8    31.59        168.0             100.0        121.6\n",
       " 3            178.4    28.29        168.1             100.0        121.1\n",
       " 4            180.7    30.33        168.1             100.4        124.5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = merged_df.PWHEAMTUSDM  # target\n",
    "\n",
    "features = ['PCU325311325311', 'WTISPLC', 'WPUSI024011', 'PCU3253203253201', 'WPU02550304']\n",
    "\n",
    "X = merged_df[features]\n",
    "\n",
    "y.head(), X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf991e7",
   "metadata": {},
   "source": [
    "Now, before running the `Random Forest` regressor, we must recall that a random forest consists of decision trees. This means it is in our best interest optimize and control the number of tree nodes to ensure the `mean absolute error`, more commonly known as `mae`, is minimal. The `mae` is the mean variance between any significant values in a dataset and its predicted values in the same dataset.\n",
    "\n",
    "$$\n",
    "\\text{mae} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|\n",
    "$$\n",
    "- $n$ is the number of data points.\n",
    "- $y_{i}$ represents the actual values.\n",
    "- $\\hat{y}_i$ represents the predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96d7a7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum leaf nodes: 5  \t\t MAE:  28.021280\n",
      "Maximum leaf nodes: 10  \t\t MAE:  23.516511\n",
      "Maximum leaf nodes: 15  \t\t MAE:  21.407904\n",
      "Maximum leaf nodes: 20  \t\t MAE:  21.059343\n",
      "Maximum leaf nodes: 25  \t\t MAE:  20.015448\n",
      "Maximum leaf nodes: 30  \t\t MAE:  20.823434\n",
      "Maximum leaf nodes: 35  \t\t MAE:  22.145005\n",
      "Maximum leaf nodes: 40  \t\t MAE:  20.538357\n",
      "Maximum leaf nodes: 45  \t\t MAE:  20.236992\n",
      "Maximum leaf nodes: 50  \t\t MAE:  19.783986\n",
      "Maximum leaf nodes: 55  \t\t MAE:  20.399856\n",
      "Maximum leaf nodes: 60  \t\t MAE:  20.040448\n",
      "Maximum leaf nodes: 65  \t\t MAE:  20.091223\n",
      "Maximum leaf nodes: 70  \t\t MAE:  19.916765\n",
      "Maximum leaf nodes: 75  \t\t MAE:  19.846544\n",
      "Maximum leaf nodes: 80  \t\t MAE:  19.892061\n",
      "Maximum leaf nodes: 85  \t\t MAE:  20.135384\n",
      "Maximum leaf nodes: 90  \t\t MAE:  20.116455\n",
      "Maximum leaf nodes: 95  \t\t MAE:  19.934180\n"
     ]
    }
   ],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=0)\n",
    "\n",
    "def mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n",
    "    model.fit(train_X, train_y)\n",
    "    predsVal = model.predict(val_X)\n",
    "    mae = mean_absolute_error(val_y, predsVal)\n",
    "    return(mae)\n",
    "\n",
    "for maxLeafNodes in [i for i in range(5, 100, 5)]:  # arbitrary range with arbitrary step\n",
    "    myMAE = mae(maxLeafNodes, train_X, val_X, train_y, val_y)\n",
    "    print(\"Maximum leaf nodes: %d  \\t\\t MAE:  %f\" %(maxLeafNodes, myMAE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81663a7",
   "metadata": {},
   "source": [
    "It can be seen that the maximum number of leaf nodes that yields the least `mae` is `50`. Thus, this is the number we shall use to parse into the `Random Forest` regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a4b87ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.265313035013865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([226.0551411 , 149.38400645, 193.34329415, 169.61499281,\n",
       "       194.60195641, 205.030027  , 182.97882485, 138.91471611,\n",
       "       254.48877724, 231.77208219, 294.8747441 , 168.85776009,\n",
       "       201.56327408, 170.72712442, 142.50454427, 168.56282051,\n",
       "       338.71527613, 272.89165702, 343.65565893, 283.79979447,\n",
       "       168.68128052, 240.52735284, 141.03702303, 257.65873704,\n",
       "       172.84364076, 183.78371617, 179.20828766, 299.84087502,\n",
       "       300.99901937, 291.23099129, 284.27033762, 139.36115797,\n",
       "       167.02887437, 286.51957068, 253.23517741, 135.25138239,\n",
       "       125.87659617, 254.64037272, 138.69970016, 158.05258104,\n",
       "       263.3007092 , 410.69276945, 283.97688186, 157.8322262 ,\n",
       "       209.26343157, 186.05641414, 312.23377776, 256.44955948,\n",
       "       201.19514039, 341.86227781, 286.31786826, 127.2015398 ,\n",
       "       174.67387697, 127.41905477, 208.65684035, 138.93054271,\n",
       "       407.93793371, 197.21257077, 189.05481136, 138.03765361,\n",
       "       239.14492759, 247.94441134, 316.69485585])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestTreeSize = 50\n",
    "\n",
    "forestModel = RandomForestRegressor(random_state=1, max_leaf_nodes=bestTreeSize)\n",
    "forestModel.fit(train_X, train_y)\n",
    "wheatPredictions = forestModel.predict(val_X)\n",
    "\n",
    "print(mean_absolute_error(val_y, wheatPredictions))\n",
    "\n",
    "wheatPredictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f259649f",
   "metadata": {},
   "source": [
    "The array displayed above contains the predicted wehat prices for the next five years and three months, given the provided training data.\n",
    "\n",
    "### do more economic analysis and adv/disadv later"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
