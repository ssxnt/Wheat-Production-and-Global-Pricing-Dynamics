{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final exam practice questions\n",
    "\n",
    "#### Question 1\n",
    "In this question, we will create a function to generate linear data step-by-step. \n",
    "1. Define a function called `gen_lin_data` that takes as its input an integer `n`, and returns a matrix `X` and a vector `Y`. \n",
    "2. First we will generate `X`. Within the function,\n",
    " - Create two random (numpy) vectors of size `n` named `X_1` and `X_2` where \n",
    "    - Each element of `X_1` is independent and distributed according to the Uniform(-2,2) distribution\n",
    "    - Each element `X_2` is independent and distributed according to the Normal(2,2) distribution. \n",
    "    \n",
    "  - Finally, concatenate `X_1` and `X_2` to generate `X` so that `X` is a numpy object with `n` rows and 2 columns.\n",
    "\n",
    "\n",
    "3. Now we will work towards generating `Y`. Within the function,\n",
    "  - Define a numpy array called `beta` and set it equal to `[-1,2]`. \n",
    "  - Define another `n` dimensional vector called `eps` where each element is independent and distributed according to the Normal(0,1/2) distribution. \n",
    "  - Finally, Generate a vector of size `n` called `Y` according to the following equation:\n",
    "$$\n",
    "Y = X \\cdot \\beta + eps\n",
    "$$\n",
    "4. Now that your function is defined, test your function in the designated cell and call it with **`n` equal to 500**. Save the resulting arrays as `Y500` and `X500`. **Print** the average of `Y500`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your function here\n",
    "import numpy as np\n",
    "\n",
    "def gen_lin_data(n):\n",
    "    X_1 = np.random.uniform(-2,2,size=n)\n",
    "    X_2 = np.random.normal(2,2,size=n)\n",
    "    X = np.column_stack((X_1,X_2))\n",
    "    beta = np.array([-1,2])\n",
    "    eps = np.random.normal(0,1/2,size=n)\n",
    "    Y = np.dot(X,beta) + eps\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.803125339392462\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10) #ignore this line and do not delete it\n",
    "\n",
    "# Define Y500 and X500 below this line:\n",
    "X500,Y500 = gen_lin_data(500)\n",
    "# Your code here\n",
    "print(Y500.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2\n",
    "In this question, we will create our own function to perform basic OLS estimation.\n",
    "1. Define a function called `simple_OLS` that takes a vector `Y` and a matrix `X` as inputs and returns a vector of OLS (linear regression) coefficient estimates. **To get full marks, you must explicitly calculate the OLS coefficients using the analytical formula for linear regression.** You will get some partial credit for estimating the equations using another method.\n",
    "2. **In the Markdown Cell below your function**, answer this question: If `y` is an $n$-vector and `X` is an $n\\times d$ matrix, what are the dimensions of the objects that will be output by the `simple_OLS` function? Verify this with your code or justify it using linear algebra.\n",
    "3. In the designated cell, define `beta_hat` to be the output of `simple_OLS` using `Y500` and `X500` from the previous problem.\n",
    "4. In the second provided Markdown Cell, explain what values you would expect the entries of `beta_hat` to be close to, and why.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your function here\n",
    "def simple_OLS(X,Y):\n",
    "    beta_hats = np.linalg.solve(X.T @ X, X.T @ Y)\n",
    "    return beta_hats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will get a dxn matrix showing all the coefficient estimates for each regression equation we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.98368016  1.99845442]\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "# Define beta_hat here\n",
    "beta_hat = simple_OLS(X500,Y500)\n",
    "print(beta_hat)\n",
    "print(beta_hat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would expect the values to be close to -1 and 2, which are the initial coefficient values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3\n",
    "In this question, we will evaluate the performance of our OLS estimator. \n",
    "1. Define a function called `simple_eval` that takes `X`, `Y`, and `beta_hat` as inputs and returns `est_mse`, the mean-squared error of `beta_hat`. \n",
    "2. Within that function\n",
    "    - Define `Yhat` to be the predicted values of `beta_hat` appled to `X`. \n",
    "    - Calculate the mean-squared error and set it to `est_mse`. To do this, you can either use the metrics module from scikitlearn or calculate the mean-squared error by hand. \n",
    "3. In the cell below your function, call your `simple_eval` function using `X500`, `Y500`, and `beta_hat` from Question 2. Save that value to a variable called `ols_mse`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your function here\n",
    "def simple_eval(X,Y,beta_hat):\n",
    "    Yhat = np.dot(X,beta_hat)\n",
    "    residuals = Y - Yhat\n",
    "    est_mse = np.mean(residuals ** 2)\n",
    "    return est_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2335128919003309"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define ols_mse here\n",
    "ols_mse = simple_eval(X500,Y500,beta_hat)\n",
    "ols_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4\n",
    "Now, fit a single regression tree on `Y500` and `X500`. Set the `random_state` and `max_depth` arguments equal to 123 and 10 respectively. Calculate the resulting training mean-squared error of this tree and set it equal to `tree_mse`.\n",
    "\n",
    "Is the MSE from this regression tree lower or higher than the mean-squared error from linear regression (OLS)? Why would that be? Enter your answer in the markdown cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean-squared error of the tree: 0.018038859089902624\n"
     ]
    }
   ],
   "source": [
    "# Fit Tree Here\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import tree, metrics\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(random_state=123, max_depth=10)\n",
    "tree_reg.fit(X500, Y500)\n",
    "\n",
    "Yhat_tree = tree_reg.predict(X500)\n",
    "\n",
    "tree_mse = mean_squared_error(Y500, Yhat_tree)\n",
    "\n",
    "print(\"Training mean-squared error of the tree:\", tree_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MSE from the regression tree is lower than that of the OLS regression. This is because it is overfitting the training data we are using."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5\n",
    "Now we will generate test data by using `gen_lin_data` with `n` equal to 200. Save the resulting arrays as `X200` and `Y200`. Using `simple_eval` and this testing data, calculate the testing mean-squared error of the `beta_hat` estimate from Question 2. Do the same for tree estimator from Question 4. In the Markdown cell below, answer the following question: Which estimator has a lower test mean-squared error? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22798934969660486\n",
      "0.001410974261751797\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "X200,Y200 = gen_lin_data(200)\n",
    "ols_mse_2 = simple_eval(X200,Y200,beta_hat)\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(random_state=123, max_depth=10)\n",
    "tree_reg.fit(X200, Y200)\n",
    "\n",
    "print(ols_mse_2)\n",
    "\n",
    "tree_mse_test = metrics.mean_squared_error(Y200,tree_reg.predict(X200))\n",
    "print(tree_mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regression tree has a lower mse because the model is overfitting and we are testing out-of-sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
